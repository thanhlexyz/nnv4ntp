Abstract—Deep learning presents a promising approach to
optimizing wireless communication by simplifying the search
for nearly optimal solutions. Previous studies have suggested
using supervised learning to map raw user information, such
as location and channel data, to an approximate optimal power
allocation vector. While this approach demonstrates competitive
performance, it is susceptible to adversarial attacks via input
perturbations. Current defense mechanisms primarily rely on
empirical methods, which do not provide formal guarantees of ro-
bustness. We propose a formal verification framework that offers
evaluation of robustness for deep neural network-based power
allocation in multi-cell massive multiple-input multiple-output
(MIMO) systems against a wide range of potential adversarial
input manipulations. We model the adversary’s capabilities using
hyperrectangle constraints on their adversarial perturbation,
adopt the abstraction-based bound-propagation technique (Deep-
Poly) for verifying neural networks, and formulate performance
requirements affected by attacks as a non-convex optimization
problem for feasibility analysis. Evaluation on publicly available
datasets for power allocation in multi-cell massive MIMO, ac-
cessible at [IEEE MLC Data](https://data.ieeemlc.org/Ds2Detail),
indicates that our framework provides strong robustness guar-
antees. For example, a well-trained model achieves 97.6% local
robustness for perturbation levels of up to ± 1m while allowing
a 1% optimality gap tolerance.
